<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Julia Tomas-Barba </title>
    <!-- Bootstrap CSS for styling -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0-alpha1/dist/css/bootstrap.min.css" rel="stylesheet">
    <style>
        body {
            font-family: Arial, sans-serif;
            background-color: #f8f9fa;
        }
        header {
            background-color: #007bff;
            color: white;
            padding: 20px 0;
            text-align: center;
        }
        footer {
            background-color: #343a40;
            color: white;
            text-align: center;
            padding: 10px 0;
            margin-top: 20px;
        }
        .container {
            margin-top: 20px;
        }
    </style>
</head>
<body>
    <!-- Header -->
    <header>
        <h1>Julia Tomás Barba</h1>
        <p>PhD Student in Systems and Informatics Engineering at the University of Zaragoza</p>
    </header>

    <!-- Main content -->
    <div class="container">
        <!-- About Me -->
        <section id="about-me" class="mb-5">
            <h2>About Me</h2>
            <p>I graduated in Industrial Technologies Engineering in 2021 and later completed a Master’s degree in Industrial Engineering in 2023. Currently, I am a PhD student in Systems and Automation Engineering at the University of Zaragoza, focusing on the application of artificial intelligence to visual prostheses.</p>
        </section>

        <!-- Research -->
        <section id="research" class="mb-5">
            <h2>Research</h2>
            <p>My research is focused on advancing the field of visual prostheses through the integration of deep learning techniques. I am working on two main areas to enhance the quality of artificial vision. First, I aim to improve the information captured by the prosthesis from the external environment using computer vision technologies, such as object detection and scene understanding. Second, I am optimizing the visual stimuli delivered to the user through deep learning models, which can be trained to adapt the stimuli to the specific needs of each individual. By combining these approaches, my goal is to create visual prostheses that not only capture the surrounding environment more effectively, but also provide the user with the most useful and precise visual feedback possible, ultimately improving the quality of life for individuals with visual impairments.</p>
        </section>

        <!-- Publications -->
        <section id="publications" class="mb-5">
            <h2>Publications</h2>
            <ul>
                <li>
                    <a href="https://iplab.dmi.unict.it/acvr2024/program/Transformer-based%20encoder.pdf" target="_blank">
                      <strong>Transformer-based encoder for improving perception in visual prosthesis</strong>
                    </a><br>
                    <em>ACVR </em>, 2024
                    <br>Co-authors: 
                    <strong>Julia Tomas-Barba</strong>,
                    <a href="https://orcid.org/0000-0002-8949-2632" target="_blank"> Alejandro Perez-Yus</a>, 
                    <a href="https://orcid.org/0000-0002-8479-1748" target="_blank"> Jesus Bermudez-Cameo</a>,
                    <a href="https://orcid.org/0000-0001-5209-2267" target="_blank"> Jose J. Guerrero</a>,
                
                </li>
                <li>
                    <a href="https://doi.org/10.1109/ACCESS.2024.3357400" target="_blank">
                      <strong>Raspv: A robotics framework for augmented simulated prosthetic vision</strong>
                    </a><br>
                    <em>IEEE Access</em>, 2024
                    <br>Co-authors: 
                    <a href="https://orcid.org/0000-0002-8949-2632" target="_blank"> Alejandro Perez-Yus</a>, 
                    <a href="https://orcid.org/0009-0009-5663-3185" target="_blank"> Maria Santos-Villafranca</a>, 
                    <strong>Julia Tomas-Barba</strong>,
                    <a href="https://orcid.org/0000-0002-8479-1748" target="_blank"> Jesus Bermudez-Cameo</a>,
                    <a href="https://orcid.org/0000-0003-0190-9331" target="_blank"> Lorenzo Montano-Olivan</a>,
                    <a href="https://orcid.org/0000-0001-9347-5969" target="_blank"> Gonzalo Lopez-Nicolas</a>,
                    <a href="https://orcid.org/0000-0001-5209-2267" target="_blank"> Jose J. Guerrero</a>,
                
                </li>
                <li>
                    <a href="https://doi.org/10.17979/spudc.9788497498609.879" target="_blank">
                        <strong>Simulador inmersivo de visión protésica modelando estímulos espacio-temporales</strong>
                    </a><br>
                    <em>XLIV Jornadas de Automática, 879-884</em>, 2023
                    <br>Co-authors: 
                    <a href="https://orcid.org/0009-0009-5663-3185" target="_blank"> Maria Santos-Villafranca</a>, 
                    <strong>Julia Tomas-Barba</strong>,
                    <a href="https://orcid.org/0000-0002-8949-2632" target="_blank"> Alejandro Perez-Yus</a>, 
                    <a href="https://orcid.org/0000-0002-8479-1748" target="_blank"> Jesus Bermudez-Cameo</a>,
                    
                </li>
                <li>
                    <a href="https://doi.org/10.26754/jjii3a.202410640" target="_blank">
                        <strong>Enhancing Realism in Simulated Prosthetic Vision by Introducing Temporal Models</strong>
                    </a><br>
                    <em>Jornada de Jóvenes Investigadores del I3A</em>, 2024
                    <br>Co-authors: 
                    <strong>Julia Tomas-Barba</strong>,
                    <a href="https://orcid.org/0000-0002-8949-2632" target="_blank"> Alejandro Perez-Yus</a>, 
                    <a href="https://orcid.org/0000-0002-8479-1748" target="_blank"> Jesus Bermudez-Cameo</a>,
                    
                </li>
            </ul>
            <p>For a complete list of publications, visit my Google Scholar profile: <a href="https://scholar.google.es/citations?user=wmCwftoAAAAJ&hl=fr" target="_blank">Google Scholar</a>.</p>
        </section>
    </div>

    <!-- Footer -->
    <footer>
        <p>&copy; 2024 Julia Tomás Barba. All rights reserved.</p>
    </footer>
</body>
</html>

